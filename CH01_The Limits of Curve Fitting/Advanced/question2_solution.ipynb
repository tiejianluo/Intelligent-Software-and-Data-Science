{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model AUC on Validation Set: 0.949\n",
      "\n",
      "Causal Consistency Test Results:\n",
      "Proportion consistent with business direction: 0.0\n",
      "Average reduction in delay probability: -0.0\n",
      "\n",
      "Causal Consistency Conclusion: Inconsistent\n",
      "\n",
      "Implementing correction plan: Feature decoupling (separating truck_allocation from confounding features)\n",
      "\n",
      "Causal Consistency Results After Correction:\n",
      "Corrected proportion consistent with business direction: 0.0\n",
      "Corrected average probability reduction: -0.001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "df = pd.read_csv(\"logistics_delay_dataset.csv\")\n",
    "# Features and target (focusing on actionable feature truck_allocation)\n",
    "features = [\n",
    "    \"weather_severity\", \"traffic_congestion\", \"warehouse_congestion\",\n",
    "    \"driver_experience\", \"truck_allocation\", \"route_complexity\",\n",
    "    \"package_volume\", \"time_sensitivity\"\n",
    "]\n",
    "X = df[features]\n",
    "y = df[\"delayed\"]\n",
    "\n",
    "# Split into training set and intervention experiment set (using subset marked with intervention)\n",
    "intervention_mask = df[\"split\"] == \"intervention\"  # Assuming dataset has split column marking intervention subset\n",
    "X_interv, y_interv = X[intervention_mask], y[intervention_mask]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[~intervention_mask], y[~intervention_mask], test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Train Baseline Model\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Baseline Model AUC on Validation Set:\", round(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]), 3))\n",
    "\n",
    "# 3. Construct Virtual Intervention Experiment\n",
    "def causal_consistency_test(model, X_interv, actionable_feature=\"truck_allocation\"):\n",
    "    \"\"\"\n",
    "    Causal consistency test: Change actionable feature and check if prediction direction aligns with business logic\n",
    "    Business logic: When truck_allocation increases from 0→1 (more trucks), delay probability should decrease\n",
    "    \"\"\"\n",
    "    # Copy experiment data, set actionable feature to 0 and 1 respectively\n",
    "    X_interv_0 = X_interv.copy()\n",
    "    X_interv_0[actionable_feature] = 0  # Before intervention: no additional trucks\n",
    "    X_interv_1 = X_interv.copy()\n",
    "    X_interv_1[actionable_feature] = 1  # After intervention: add trucks\n",
    "    \n",
    "    # Predict delay probabilities\n",
    "    prob_0 = model.predict_proba(X_interv_0)[:, 1]\n",
    "    prob_1 = model.predict_proba(X_interv_1)[:, 1]\n",
    "    \n",
    "    # Calculate proportion of samples consistent with business direction (prob_1 < prob_0)\n",
    "    consistent_ratio = np.mean(prob_1 < prob_0)\n",
    "    # Calculate average probability change\n",
    "    avg_prob_change = np.mean(prob_0 - prob_1)\n",
    "    \n",
    "    return {\n",
    "        \"Proportion consistent with business direction\": round(consistent_ratio, 3),\n",
    "        \"Average reduction in delay probability\": round(avg_prob_change, 3),\n",
    "        \"prob_0 (before intervention)\": prob_0,\n",
    "        \"prob_1 (after intervention)\": prob_1\n",
    "    }\n",
    "\n",
    "# Execute causal consistency test\n",
    "test_result = causal_consistency_test(model, X_interv)\n",
    "print(\"\\nCausal Consistency Test Results:\")\n",
    "for k, v in test_result.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "# Determine consistency (threshold: proportion ≥ 0.7 considered consistent)\n",
    "is_consistent = test_result[\"Proportion consistent with business direction\"] >= 0.7\n",
    "print(f\"\\nCausal Consistency Conclusion: {'Consistent' if is_consistent else 'Inconsistent'}\")\n",
    "\n",
    "# 4. If inconsistent, implement correction plan (using feature decoupling as example)\n",
    "if not is_consistent:\n",
    "    print(\"\\nImplementing correction plan: Feature decoupling (separating truck_allocation from confounding features)\")\n",
    "    \n",
    "    # Feature decoupling: Use residual method to eliminate confounding between truck_allocation and weather_severity (assuming they are correlated)\n",
    "    # Step 1: Predict weather_severity using truck_allocation, take residuals as \"deconfounded weather feature\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train[[\"truck_allocation\"]], X_train[\"weather_severity\"])\n",
    "    X_train[\"weather_severity_resid\"] = X_train[\"weather_severity\"] - lr.predict(X_train[[\"truck_allocation\"]])\n",
    "    X_val[\"weather_severity_resid\"] = X_val[\"weather_severity\"] - lr.predict(X_val[[\"truck_allocation\"]])\n",
    "    X_interv[\"weather_severity_resid\"] = X_interv[\"weather_severity\"] - lr.predict(X_interv[[\"truck_allocation\"]])\n",
    "    \n",
    "    # Step 2: Retrain model with new features (replacing original weather_severity)\n",
    "    new_features = [f for f in features if f != \"weather_severity\"] + [\"weather_severity_resid\"]\n",
    "    model_corrected = GradientBoostingClassifier(random_state=42)\n",
    "    model_corrected.fit(X_train[new_features], y_train)\n",
    "    \n",
    "    # Step 3: Re-test causal consistency\n",
    "    def corrected_causal_test(model, X_interv, new_features, actionable_feature=\"truck_allocation\"):\n",
    "        X_interv_0 = X_interv.copy()\n",
    "        X_interv_0[actionable_feature] = 0\n",
    "        X_interv_1 = X_interv.copy()\n",
    "        X_interv_1[actionable_feature] = 1\n",
    "        prob_0 = model.predict_proba(X_interv_0[new_features])[:, 1]\n",
    "        prob_1 = model.predict_proba(X_interv_1[new_features])[:, 1]\n",
    "        return {\n",
    "            \"Corrected proportion consistent with business direction\": round(np.mean(prob_1 < prob_0), 3),\n",
    "            \"Corrected average probability reduction\": round(np.mean(prob_0 - prob_1), 3)\n",
    "        }\n",
    "    \n",
    "    corrected_result = corrected_causal_test(model_corrected, X_interv, new_features)\n",
    "    print(\"\\nCausal Consistency Results After Correction:\")\n",
    "    for k, v in corrected_result.items():\n",
    "        print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu_assist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
