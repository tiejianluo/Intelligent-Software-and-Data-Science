{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\"\"\"\n",
    "To install pyro, run the following command:\n",
    "pip install pyro-ppl\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def prepare_data_for_model(df):\n",
    "    \"\"\"\n",
    "    Prepare data for Pyro hierarchical Bayesian model\n",
    "    \n",
    "    Input:\n",
    "    - df: pandas DataFrame containing raw categorical data\n",
    "    \n",
    "    Output:\n",
    "    - encoded_data: Dictionary of encoded numerical data\n",
    "    - encoders: Dictionary of encoders for reverse transformation\n",
    "    \n",
    "    Function:\n",
    "    - Encode string categorical variables to numerical values\n",
    "    - Prepare appropriate data format for hierarchical model\n",
    "    \"\"\"\n",
    "    encoders = {}\n",
    "    encoded_data = {}\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_columns = ['user_segment', 'region', 'ad_campaign', 'ad_intensity', 'click_behavior']\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        encoded_data[col] = torch.tensor(le.fit_transform(df[col]), dtype=torch.long)\n",
    "        encoders[col] = le\n",
    "    \n",
    "    # Encode target variable (purchase decision)\n",
    "    purchase_encoder = LabelEncoder()\n",
    "    encoded_data['purchase_decision'] = torch.tensor(\n",
    "        purchase_encoder.fit_transform(df['purchase_decision']), dtype=torch.long\n",
    "    )\n",
    "    encoders['purchase_decision'] = purchase_encoder\n",
    "    \n",
    "    # Add numerical features\n",
    "    encoded_data['session_duration'] = torch.tensor(\n",
    "        df['session_duration_sec'].values, dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    return encoded_data, encoders\n",
    "\n",
    "def hierarchical_bayesian_model(encoded_data):\n",
    "    \"\"\"\n",
    "    Two-level Hierarchical Bayesian Model: User segment level and ad campaign level\n",
    "    \n",
    "    Input:\n",
    "    - encoded_data: Dictionary of encoded data\n",
    "    \n",
    "    Output:\n",
    "    - Model trace (via Pyro sampling)\n",
    "    \n",
    "    Function:\n",
    "    - Build random effects at user segment level\n",
    "    - Build random effects at ad campaign level\n",
    "    - Model multi-level influencing factors of purchase decisions\n",
    "    \"\"\"\n",
    "    n_obs = len(encoded_data['purchase_decision'])\n",
    "    n_user_segments = len(torch.unique(encoded_data['user_segment']))\n",
    "    n_ad_campaigns = len(torch.unique(encoded_data['ad_campaign']))\n",
    "    \n",
    "    with pyro.plate(\"data\", n_obs):\n",
    "        # Level 1: Random effects at user segment level\n",
    "        with pyro.plate(\"user_segments\", n_user_segments):\n",
    "            user_intercept = pyro.sample(\n",
    "                \"user_intercept\", \n",
    "                dist.Normal(0, 1)\n",
    "            )\n",
    "            user_effect = pyro.sample(\n",
    "                \"user_effect\",\n",
    "                dist.Normal(user_intercept, 0.5)\n",
    "            )\n",
    "        \n",
    "        # Level 2: Random effects at ad campaign level\n",
    "        with pyro.plate(\"ad_campaigns\", n_ad_campaigns):\n",
    "            ad_intercept = pyro.sample(\n",
    "                \"ad_intercept\",\n",
    "                dist.Normal(0, 1)\n",
    "            )\n",
    "            ad_effect = pyro.sample(\n",
    "                \"ad_effect\", \n",
    "                dist.Normal(ad_intercept, 0.5)\n",
    "            )\n",
    "        \n",
    "        # Influence of click behavior\n",
    "        click_coef = pyro.sample(\"click_coef\", dist.Normal(0, 1))\n",
    "        \n",
    "        # Influence of session duration\n",
    "        session_coef = pyro.sample(\"session_coef\", dist.Normal(0, 1))\n",
    "        \n",
    "        # Linear combination\n",
    "        user_contrib = user_effect[encoded_data['user_segment']]\n",
    "        ad_contrib = ad_effect[encoded_data['ad_campaign']]\n",
    "        click_contrib = click_coef * encoded_data['click_behavior'].float()\n",
    "        session_contrib = session_coef * encoded_data['session_duration'] / 100.0\n",
    "        \n",
    "        logits = user_contrib + ad_contrib + click_contrib + session_contrib\n",
    "        \n",
    "        # Observation model (purchase decision)\n",
    "        pyro.sample(\n",
    "            \"obs\", \n",
    "            dist.Categorical(logits=logits), \n",
    "            obs=encoded_data['purchase_decision']\n",
    "        )\n",
    "\n",
    "def run_bayesian_inference(df, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Run hierarchical Bayesian model inference and analyze results\n",
    "    \n",
    "    Input:\n",
    "    - df: Raw data DataFrame\n",
    "    - num_samples: Number of MCMC samples\n",
    "    \n",
    "    Output:\n",
    "    - inference_results: Dictionary containing posterior distributions and model diagnostics\n",
    "    \n",
    "    Function:\n",
    "    - Perform Bayesian inference using NUTS sampler\n",
    "    - Analyze random effects at different levels\n",
    "    - Compare uncertainty of model parameters\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    encoded_data, encoders = prepare_data_for_model(df)\n",
    "    \n",
    "    # Set Pyro random seed\n",
    "    pyro.set_rng_seed(42)\n",
    "    \n",
    "    # Use NUTS sampler\n",
    "    nuts_kernel = pyro.infer.NUTS(hierarchical_bayesian_model)\n",
    "    mcmc = pyro.infer.MCMC(\n",
    "        nuts_kernel,\n",
    "        num_samples=num_samples,\n",
    "        warmup_steps=200,\n",
    "        num_chains=2\n",
    "    )\n",
    "    \n",
    "    print(\"Starting hierarchical Bayesian model inference...\")\n",
    "    mcmc.run(encoded_data)\n",
    "    \n",
    "    print(\"\\nInference completed! Model summary:\")\n",
    "    mcmc.summary()\n",
    "    \n",
    "    # Extract posterior samples\n",
    "    posterior_samples = mcmc.get_samples()\n",
    "    \n",
    "    # Analyze results\n",
    "    results = {\n",
    "        'mcmc': mcmc,\n",
    "        'posterior_samples': posterior_samples,\n",
    "        'encoders': encoders,\n",
    "        'user_effects': posterior_samples['user_effect'].mean(dim=0),\n",
    "        'ad_effects': posterior_samples['ad_effect'].mean(dim=0)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nUser Segment Level Effects:\")\n",
    "    for i, effect in enumerate(results['user_effects']):\n",
    "        segment_name = encoders['user_segment'].inverse_transform([i])[0]\n",
    "        print(f\"  {segment_name}: {effect:.3f}\")\n",
    "    \n",
    "    print(\"\\nAd Campaign Level Effects:\")\n",
    "    for i, effect in enumerate(results['ad_effects']):\n",
    "        campaign_name = encoders['ad_campaign'].inverse_transform([i])[0]\n",
    "        print(f\"  {campaign_name}: {effect:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run hierarchical Bayesian analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_csv('causal_advertising_data.csv')\n",
    "    \n",
    "    # Run Bayesian inference\n",
    "    bayesian_results = run_bayesian_inference(df, num_samples=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu_assist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
