# Solutions of Advanced Exercises in Chapter 3

This repository contains two solutions for the advanced problems from **Chapter 3: Foundations of Probabilistic Modeling**, demonstrating practical implementations of Bayesian inference methods.

## ğŸ“ Files Overview

### 1. `question1_solution.ipynb` - Variational Inference with Gaussian Approximation

**Problem Statement**: Implement a minimal VI routine with a Gaussian `q(Î¸)`; plot ELBO convergence.

#### ğŸ”§ Key Features
- **Core Algorithm**: Variational Inference with Gaussian variational posterior
- **Distribution**: Uses Gaussian `q(Î¸) = N(Î¼, ÏƒÂ²)` to approximate true posterior
- **Optimization**: Maximizes Evidence Lower Bound (ELBO) via gradient descent
- **Visualization**: ELBO convergence tracking and posterior distribution comparison

#### ğŸ“Š Inputs
- **Generated Data**: 100 samples from true Gaussian distribution `N(3.0, 1.5)`
- **Prior**: Gaussian prior `p(Î¸) = N(0, 3)`
- **Likelihood**: Gaussian likelihood with fixed observation noise

#### ğŸ“ˆ Outputs
- **Optimized Parameters**: Variational mean `Î¼` and standard deviation `Ïƒ`
- **Convergence Plot**: ELBO values over training epochs
- **Distribution Comparison**: True posterior vs. variational approximation
- **Performance Metrics**: Final parameter estimates vs. ground truth

#### ğŸš€ Usage
```python
# Generate data and run training
x = generate_data(n_samples=100)
q, elbo_history = train_vi(x, num_epochs=1000, lr=0.01)

# Access results
final_mu = q.mu.item()
final_sigma = torch.nn.functional.softplus(q.log_sigma).item()
```

---

### 2. `question2_solution.ipynb` - Beta-Binomial Model for FastShip Forecasting

**Problem Statement**: Embed the Betaâ€“Binomial updater into FastShip's rolling forecast; report credible intervals over time.

#### ğŸ”§ Key Features
- **Core Model**: Bayesian Beta-Binomial conjugate model with rolling updates
- **Comparison**: Traditional sliding window model vs. Bayesian approach
- **Anomaly Detection**: Special handling for holiday periods with significant fluctuations
- **Uncertainty Quantification**: 95% credible intervals for all predictions

#### ğŸ“Š Inputs
- **Simulated Data**: 14 days of hourly shipment fulfillment data (336 periods)
- **Special Events**: 5 holiday periods with enhanced fulfillment probabilities
- **Base Configuration**: Initial Beta parameters `Î±=2, Î²=5`

#### ğŸ“ˆ Outputs
- **Time Series Forecasts**: Rolling probability predictions
- **Credible Intervals**: 95% Bayesian confidence bounds
- **Performance Metrics**: MAE scores (overall and holiday-specific)
- **Comparative Analysis**: Bayesian vs. traditional model performance

#### ğŸ“Š Key Metrics
- **Overall MAE**: Model accuracy across entire timeline
- **Holiday MAE**: Specialized performance during anomalous periods
- **Uncertainty Bounds**: Dynamic credible intervals reflecting model confidence

#### ğŸš€ Usage
```python
# Generate shipment data with holiday effects
timestamps, outcomes, true_probs, holiday_indices = generate_shipment_data()

# Run Bayesian model
bayes_results = beta_binomial_model(outcomes)

# Run traditional model for comparison  
traditional_results = sliding_window_model(outcomes)

# Evaluate performance
bayes_mae = calculate_mae(bayes_results['pred'], true_probs)
```

## ğŸ¯ Problem Solutions

### Question 1 Solution
Demonstrates a complete variational inference pipeline:
- âœ… Implements Gaussian variational posterior `q(Î¸)`
- âœ… Optimizes ELBO via gradient-based methods
- âœ… Provides convergence monitoring through ELBO plots
- âœ… Shows posterior approximation quality vs. true distribution

### Question 2 Solution  
Shows practical Bayesian forecasting:
- âœ… Embeds Beta-Binomial updater in rolling forecast system
- âœ… Reports time-varying credible intervals
- âœ… Handles real-world challenges (holiday anomalies)
- âœ… Provides comparative analysis vs. traditional methods

## ğŸ“‹ Dependencies

- **Question 1**: `numpy`, `matplotlib`, `torch`
- **Question 2**: `numpy`, `matplotlib`, `scipy`, `pandas`, `datetime`

Both solutions are self-contained and include all necessary data generation and visualization components.